{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b9f2af-c236-4089-8fbc-00d3000001b0",
   "metadata": {},
   "source": [
    "# Projet Question Answering - Annexes\n",
    "\n",
    "Ne pas hésiter à retélécharger ce fichier régulièrement pour voir si le\n",
    "contenu a évolué.\n",
    "\n",
    "## Installation de pyserini\n",
    "\n",
    "L’installation est assez délicate, les instruction suivantes sont\n",
    "inspirées de\n",
    "<https://github.com/castorini/pyserini/blob/master/docs/installation.md>:\n",
    "\n",
    "``` shell\n",
    "conda create -n pyserini python=3.10 -y\n",
    "conda activate pyserini\n",
    "conda install -c conda-forge openjdk=11 maven -y\n",
    "conda install -c conda-forge lightgbm nmslib -y\n",
    "conda install -c pytorch faiss-cpu mkl=2021 blas=1.0=mkl pytorch -y\n",
    "pip install pyserini\n",
    "```\n",
    "\n",
    "Une version sans conda devrait marcher aussi, à condition d’avoir Python\n",
    "3.10 et pas une version plus récente:\n",
    "\n",
    "``` shell\n",
    "python -m venv serini\n",
    "source serini/bin/activate\n",
    "sudo apt update\n",
    "sudo apt install default-jdk build-essential\n",
    "pip install faiss-cpu\n",
    "pip install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "pip install pyserini\n",
    "```\n",
    "\n",
    "## Installation des modules Huggingface\n",
    "\n",
    "``` shell\n",
    "pip install datasets\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "Ces deux bibliothèques gèrent le téléchargement des datasets et des\n",
    "modèles pré-entraînés. Le téléchargement se fait une fois pour toute\n",
    "lors de la première exécution.\n",
    "\n",
    "## Installation de Langchain\n",
    "\n",
    "``` shell\n",
    "pip install langchain\n",
    "```\n",
    "\n",
    "## Chargement du dataset `nq_open`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b02eb4e2-0a24-4b5b-839b-1084b3513645",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnq_open\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39miter(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nq_open\", split=\"validation\")\n",
    "for batch in dataset.iter(batch_size=1):\n",
    "    print(batch[\"question\"], batch[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6d68c-fd0e-4347-a721-13e144dbec52",
   "metadata": {},
   "source": [
    "## Modèle probabiliste avec Pyserini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09cf96-6dfd-417b-a02e-aa5a098ecbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "\n",
    "searcher = LuceneSearcher.from_prebuilt_index('wikipedia-dpr-100w')\n",
    "hits = searcher.search('How old is Harrisson Ford ?')\n",
    "\n",
    "for i in range(0, 10):\n",
    "    docid = hits[i].docid\n",
    "    score = hits[i].score\n",
    "    content = json.loads(searcher.doc(docid).raw())[\"contents\"]\n",
    "\n",
    "    print(score, docid, content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa35441-8262-4e83-adc2-ecf3edc65d58",
   "metadata": {},
   "source": [
    "Cet index a été calculé à partir d’une extraction complète de wikipedia.\n",
    "Chaque article a été découpé en passages d’une longueur de 100 mots. Un\n",
    "document de l’index est l’un de ces passages.\n",
    "\n",
    "## Modèle dense avec Pyserini\n",
    "\n",
    "Ne pas l’utiliser tel quel, c’est trop coûteux pour une machine\n",
    "personnelle, ce fragment est juste donné à titre de référence. On voit\n",
    "ici l’encodeur de question\n",
    "`facebook/dpr-question_encoder-single-nq-base` et l’index précalculé\n",
    "avec l’encodeur de documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43afff3-a5fa-424b-9d53-60370a6f99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyserini.search.faiss import FaissSearcher, DprQueryEncoder\n",
    "# \n",
    "# encoder = DprQueryEncoder('facebook/dpr-question_encoder-single-nq-base')\n",
    "# searcher = FaissSearcher.from_prebuilt_index(\n",
    "#     'wikipedia-dpr-100w.dpr-single-nq',\n",
    "#     encoder\n",
    "# )\n",
    "# hits = searcher.search('what is a lobster roll')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf02b6-c220-425a-ba06-8a4e2f896050",
   "metadata": {},
   "source": [
    "Il s’agit des mêmes documents que précédemment.\n",
    "\n",
    "## Modèle dense avec Fakesearch\n",
    "\n",
    "Il faut télécharger le fichier `fakesearch.py` et le fichier\n",
    "`faiss-validation.pickle`. Les résultats de recherche ont été\n",
    "précalculés et stockés dans un fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4ba31bb-6ac6-46b7-b31e-a04e856da5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 'what is a lobster roll' not found in dense_index. Available keys: ['when was the last time anyone was on the moon', \"who wrote he ain't heavy he's my brother lyrics\", 'how many seasons of the bastard executioner are there', 'when did the eagles win last super bowl', \"who won last year's ncaa women's basketball\"] ...\n"
     ]
    }
   ],
   "source": [
    "# Make sure that fakesearch.py is downloaded and placed in the working directory.\n",
    "import fakesearch\n",
    "\n",
    "dense_index = fakesearch.load(\"faiss-validation.pickle\")\n",
    "query = \"what is a lobster roll\"\n",
    "if query in dense_index:\n",
    "\tprint(dense_index[query])\n",
    "else:\n",
    "\tprint(f\"Query '{query}' not found in dense_index. Available keys: {list(dense_index.keys())[:5]} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7315e3-848a-4a64-ad7f-12b913e9e6cb",
   "metadata": {},
   "source": [
    "Attention, on ne peut utiliser que les questions du sous-ensemble de\n",
    "validation. On obtiendra une erreur dans le cas contraire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cf43b2f-bff9-40bb-a377-f2a0b5d7f965",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'how old is harrison ford'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdense_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow old is harrison ford\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'how old is harrison ford'"
     ]
    }
   ],
   "source": [
    "dense_index[\"how old is harrison ford\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff10d36-6ec3-4cb6-90ea-6ff2e0b9357a",
   "metadata": {},
   "source": [
    "## Modèle probabiliste avec Fakesearch\n",
    "\n",
    "La recherche pré-calculée n’est à utiliser que si vous n’arrivez\n",
    "vraiment pas à installer `pyserini`.\n",
    "\n",
    "Il faut télécharger le fichier `fakesearch.py` et le fichier\n",
    "`lucence-validation.pickle`. Les résultats de recherche ont été\n",
    "précalculés et stockés dans un fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898426d-461e-4acd-bcfc-2e975b40fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fakesearch\n",
    "\n",
    "sparse_index = fakesearch.load(\"lucene-validation.pickle)\n",
    "sparse_index[\"what is a lobster roll\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ebc433-a1a1-4355-b6a8-f4e9ff4811f7",
   "metadata": {},
   "source": [
    "Attention, on ne peut utiliser que les questions du sous-ensemble de\n",
    "validation. On obtiendra une erreur dans le cas contraire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c85b4-a61a-4cd0-aec0-9d9f5b6f1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_index[\"How old is Harrison Ford\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0395db-74c7-4b5a-8266-6c7b39986145",
   "metadata": {},
   "source": [
    "## ChatGPT avec le module OpenAI\n",
    "\n",
    "Cet interface est relativement simple, mais limitée à ChatGPT et ne\n",
    "fournit aucun outil pour faciliter l’utilisation des réponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b449f872-30cc-425e-a9a7-7e6a0ce44acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who is Joe Biden ?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2f09f-c824-402b-abc7-5cf72aa18cf8",
   "metadata": {},
   "source": [
    "## ChatGPT avec Langchain\n",
    "\n",
    "Langchain est un peu plus complexe à utiliser, mais permet d’utiliser\n",
    "beaucoup plus d’outils pratiques et de s’abstraire du modèle de langue\n",
    "utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3808790-5b96-47a4-a4eb-c3ee14820316",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(openai_api_key\u001b[38;5;241m=\u001b[39mLA_CLÉ_ICI)\n\u001b[0;32m      4\u001b[0m llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is a lobster roll\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=LA_CLÉ_ICI)\n",
    "llm.invoke(\"what is a lobster roll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519f137-94c7-4524-ac4f-2c9c766ccd2c",
   "metadata": {},
   "source": [
    "## Duckduckgo avec Langchain\n",
    "\n",
    "Voir <https://python.langchain.com/docs/integrations/tools/ddg>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758efdfd-a15a-4c07-9603-49d159e87345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\pigio\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall --upgrade --quiet  duckduckgo-search\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DuckDuckGoSearchRun\n\u001b[0;32m      5\u001b[0m search \u001b[38;5;241m=\u001b[39m DuckDuckGoSearchRun()\n\u001b[0;32m      6\u001b[0m search\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is a lobster roll\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pigio\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\tools\\__init__.py:69\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _import_python_tool_PythonREPLTool()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tools\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# If not in interactive env, raise warning.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive_env():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  duckduckgo-search\n",
    "\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "search.run(\"what is a lobster roll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b6bfe-ae54-4e94-8174-fc5b1258c002",
   "metadata": {},
   "source": [
    "## Llama2\n",
    "\n",
    "Pour Llama2, on a besoin de:\n",
    "\n",
    "-   Ollama <https://ollama.ai/> pour télécharger et faire tourner le\n",
    "    modèle\n",
    "-   Langchain pour l’utiliser\n",
    "\n",
    "Voir <https://python.langchain.com/docs/integrations/chat/ollama>\n",
    "\n",
    "## GPT2\n",
    "\n",
    "Voir <https://huggingface.co/gpt2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18436d-6726-494d-b259-eed8d76e6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "pipe(\"what is a lobster roll\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
